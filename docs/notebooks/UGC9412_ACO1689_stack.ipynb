{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e2d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from du_astro_utils import calibration, photometry, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from scipy.ndimage import median_filter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3240a1-b8a4-45f6-98c9-b23b88101640",
   "metadata": {},
   "source": [
    "## Reduce Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a89845e-6e37-48e9-b9d9-ecfc845778f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_type = \"galaxy_cluster\"\n",
    "if target_type == \"asteroid\":\n",
    "    data_dir = os.path.join(utils.C2PU_DATA_DIR, utils.DIR_PHOTOM, utils.DIR_ASTER)\n",
    "elif target_type == \"exoplanet\":\n",
    "    data_dir = os.path.join(utils.C2PU_DATA_DIR, utils.DIR_PHOTOM, utils.DIR_EXPLTS)\n",
    "elif target_type == \"variable_star\":\n",
    "    data_dir = os.path.join(utils.C2PU_DATA_DIR, utils.DIR_PHOTOM, utils.DIR_VARSTARS)\n",
    "elif target_type == \"galaxy_cluster\":\n",
    "    data_dir = os.path.join(utils.C2PU_DATA_DIR, utils.DIR_PHOTOM, utils.DIR_GALCLUST)\n",
    "elif target_type == \"cluster\":\n",
    "    data_dir = os.path.join(utils.C2PU_DATA_DIR, utils.DIR_PHOTOM, utils.DIR_CLUSTERS)\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6061d3-8d20-4000-86d0-0845b6d12d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, ddir in enumerate(os.listdir(data_dir)):\n",
    "    subdata_dir = os.path.join(data_dir, ddir)\n",
    "    if os.path.isdir(subdata_dir):\n",
    "        list_fits = [im for im in sorted(os.listdir(subdata_dir)) if \".fits\" in im]\n",
    "        list_fits = sorted(list_fits)\n",
    "        print(f\"{ix} - {subdata_dir} : {len(list_fits)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386a3192-7a6e-4153-8d34-5057f881c435",
   "metadata": {},
   "outputs": [],
   "source": [
    "achoice = os.listdir(data_dir)[8]\n",
    "subdata_dir = os.path.join(data_dir, achoice)\n",
    "list_fits = sorted([im for im in sorted(os.listdir(subdata_dir)) if \".fits\" in im])\n",
    "list_fits\n",
    "im0 = os.path.join(subdata_dir, list_fits[0])\n",
    "with fits.open(im0) as hdul:\n",
    "    hdr = hdul[0].header\n",
    "print(hdr.keys)\n",
    "hdr.get(\"FOCPOS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ac5264-eb5d-415d-8fcc-39f7f6544ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in [7]:  # range(6, 10):\n",
    "    achoice = os.listdir(data_dir)[idx]\n",
    "    reduced = False\n",
    "    aligned = False\n",
    "    subdata_dir = os.path.join(data_dir, achoice)\n",
    "    if reduced:\n",
    "        subdata_dir = os.path.join(subdata_dir, \"REDUCED\")\n",
    "    if aligned:\n",
    "        subdata_dir = os.path.join(subdata_dir, \"aligned\")\n",
    "    list_fits = [im for im in sorted(os.listdir(subdata_dir)) if \".fits\" in im]\n",
    "    list_fits = sorted(list_fits)\n",
    "\n",
    "    rerun = False\n",
    "    test_mode = False  # Only runs on a few images, prints the tables at each step and does not write files.\n",
    "    # dict_of_dict = {}\n",
    "\n",
    "    if test_mode:\n",
    "        list_fits = list_fits[:10]\n",
    "    for loc, scimage in enumerate(tqdm(list_fits)):\n",
    "        fits_sci_image = os.path.join(subdata_dir, scimage)\n",
    "        fits_sci_image = os.path.abspath(fits_sci_image)\n",
    "        if os.path.isfile(fits_sci_image):\n",
    "            # Get image directory, failename and extension\n",
    "            sc_im_dir = os.path.abspath(os.path.dirname(fits_sci_image))\n",
    "            sc_im_name, sc_im_ext = os.path.splitext(os.path.basename(fits_sci_image))\n",
    "\n",
    "            bias_dir, darks_dir, flats_dir = utils.get_calib_dirs_photometry(fits_sci_image)\n",
    "            # print(bias_dir, darks_dir, flats_dir)\n",
    "\n",
    "            # Get information from FITS header\n",
    "            # sc_date, sc_scope, sc_cam, sc_filter, sc_focus, sc_expos, sc_x, sc_y = calibration.get_infos_from_image(fits_sci_image, verbose=True)\n",
    "            # print(sc_date, sc_filter, sc_focus, sc_expos)\n",
    "            # flats_list = calibration.load_flat_frames(flats_dir, sc_date, sc_cam, sc_focus, sc_filter, sc_x, sc_y, verbose=True)\n",
    "            # for flat in flats_list:\n",
    "            #    with fits.open(flat) as hdul:\n",
    "            #        hdr = hdul[0].header\n",
    "            #        print(hdr.get('FOCPOS'), hdr.get('INSTFILT'))\n",
    "\n",
    "            # Run calibration\n",
    "            # dico_calib = calibration.dedark_sci_image(fits_sci_image, override_date_check=True, max_days=7,\\\n",
    "            #                                          overwrite=rerun, verbose=False, write_tmp=test_mode,\\\n",
    "            #                                          overwrite_calibs=False)\n",
    "            calibration.reduce_sci_image(fits_sci_image, darks_dir, flats_dir, bias_dir, override_date_check=False, max_days=10, overwrite=rerun, verbose=False, write_tmp=test_mode, overwrite_calibs=(rerun and loc == 0))\n",
    "            # dict_of_dict.update({sc_im_name: dico_calib})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d848778a-e370-4b56-bdcc-824c217329bf",
   "metadata": {},
   "source": [
    "__If not done, plate-solve and align within AIJ.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3a2b95-c44d-4667-acbe-99dee85037cf",
   "metadata": {},
   "source": [
    "## Stacking images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59513ff1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(utils.C2PU_RES_DIR, utils.DIR_PHOTOM, utils.DIR_GALCLUST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d38b79-31b0-42d5-a965-f25cbc835ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = True\n",
    "aligned = True\n",
    "for ix, ddir in enumerate(os.listdir(data_dir)):\n",
    "    subdata_dir = os.path.join(data_dir, ddir)\n",
    "    if reduced:\n",
    "        subdata_dir = os.path.join(subdata_dir, \"REDUCED\")\n",
    "    if aligned:\n",
    "        subdata_dir = os.path.join(subdata_dir, \"aligned\")\n",
    "    if os.path.isdir(subdata_dir):\n",
    "        list_fits = [im for im in sorted(os.listdir(subdata_dir)) if \"REDUCED.fits\" in im]\n",
    "        list_fits = sorted(list_fits)\n",
    "        print(f\"{ix} - {subdata_dir} : {len(list_fits)} files\")\n",
    "    else:\n",
    "        print(f\"{subdata_dir} : not a directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bbb9b4-73a9-443c-a3d7-7af307abb100",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirchoice = os.listdir(data_dir)[7]\n",
    "subdata_dir = os.path.join(data_dir, dirchoice)\n",
    "if reduced:\n",
    "    subdata_dir = os.path.join(subdata_dir, \"REDUCED\")\n",
    "if aligned:\n",
    "    subdata_dir = os.path.join(subdata_dir, \"aligned\")\n",
    "if os.path.isdir(subdata_dir):\n",
    "    list_fits = [im for im in sorted(os.listdir(subdata_dir)) if \"REDUCED.fits\" in im]\n",
    "    list_fits = sorted(list_fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76d98b4-acd4-49de-b1f9-811958fed70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af149302-1f0f-449f-988a-e58bfbd6abdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_stack = False\n",
    "do_stack = True\n",
    "# combtype='MEDIAN' # SUM ou AVERAGE ou MEDIAN\n",
    "center_type = \"MOST\"\n",
    "reduced = True\n",
    "aligned = True\n",
    "if do_stack:\n",
    "    for combtype in tqdm([\"SUM\", \"MEDIAN\", \"AVERAGE\"]):\n",
    "        for filt in tqdm([\"g\", \"r\", \"i\"]):  # tqdm(['g', 'r', 'i', 'z']):\n",
    "            exp = 120  # exp = 60 if filt=='z' else 30 if filt=='i' else 15 # 10\n",
    "            dirchoice = os.listdir(data_dir)[7]  # os.listdir(data_dir)[9] if filt=='z' else os.listdir(data_dir)[8]\n",
    "            subdata_dir = os.path.join(data_dir, dirchoice)\n",
    "            if reduced:\n",
    "                subdata_dir = os.path.join(subdata_dir, \"REDUCED\")\n",
    "            if aligned:\n",
    "                subdata_dir = os.path.join(subdata_dir, \"aligned\")\n",
    "            rel_data_dir = os.path.relpath(subdata_dir)\n",
    "\n",
    "            if not manual_stack:\n",
    "                outname = f\"coadd_{dirchoice}_SDSS{filt}p_{exp:04d}s_RED_SW_{combtype}_{center_type}.fits\"\n",
    "                if not os.path.isfile(outname):\n",
    "                    swarp_cmd = f\"swarp {rel_data_dir}/*SDSS{filt}*{exp:04d}s*REDUCED.fits -c default.swarp -IMAGEOUT_NAME {outname} -COMBINE_TYPE {combtype} -CENTER_TYPE {center_type} -VERBOSE_TYPE QUIET\"\n",
    "                    os.system(swarp_cmd)\n",
    "            else:\n",
    "                if os.path.isdir(rel_data_dir):\n",
    "                    list_fits = [im for im in sorted(os.listdir(rel_data_dir)) if \"REDUCED.fits\" in im]\n",
    "                    list_fits = sorted(list_fits)\n",
    "                outname = f\"coadd_{dirchoice}_SDSS{filt}p_{exp:04d}s_RED_np{combtype}.fits\"\n",
    "                SDSS_imgs = [os.path.join(rel_data_dir, im) for im in list_fits if (f\"SDSS{filt}\" in im and f\"{exp:04d}s\" in im)]\n",
    "                if len(SDSS_imgs) > 0:\n",
    "                    if not os.path.isfile(outname):\n",
    "                        with fits.open(SDSS_imgs[0]) as hdul:\n",
    "                            ref_hdu = hdul[0].copy()\n",
    "                            SDSS_stack = np.empty((len(SDSS_imgs), *hdul[0].data.shape))\n",
    "                        for loc, fits_img in enumerate(SDSS_imgs):\n",
    "                            with fits.open(fits_img) as hdul:\n",
    "                                img_data = hdul[0].data\n",
    "                            SDSS_stack[loc, :, :] = img_data\n",
    "                            # mean, med, sigma = sigma_clipped_stats(img_data, sigma=3)\n",
    "                            # plt.imshow(img_data, cmap='gray', vmin=med-5*sigma, vmax=med+5*sigma)\n",
    "                            # plt.colorbar()\n",
    "                            # plt.show()\n",
    "                        if combtype == \"AVERAGE\":\n",
    "                            coadd_im = np.mean(SDSS_stack, axis=0)\n",
    "                        elif combtype == \"SUM\":\n",
    "                            coadd_im = np.sum(SDSS_stack, axis=0)\n",
    "                        else:  ## defaults to median\n",
    "                            coadd_im = np.median(SDSS_stack, axis=0)\n",
    "                        ref_hdu.data = coadd_im\n",
    "                        ref_hdu.writeto(outname, overwrite=True)\n",
    "\n",
    "            if os.path.isfile(outname):\n",
    "                with fits.open(outname) as hdul:\n",
    "                    img_data = hdul[0].data\n",
    "                mean, med, sigma = sigma_clipped_stats(img_data, sigma=3)\n",
    "                plt.imshow(img_data, cmap=\"gray\", vmin=med + 2 * sigma, vmax=med + 5 * sigma)\n",
    "                # plt.colorbar()\n",
    "                plt.title(outname)\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d913c5a9-5619-4bc0-aa58-7ea0eacbf726",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    for combtype in [\"SUM\", \"MEDIAN\", \"AVERAGE\"]:\n",
    "        for filt in tqdm([\"g\", \"r\", \"i\"]):  # tqdm(['g', 'r', 'i', 'z']):\n",
    "            exp = 120  # exp = 60 if filt=='z' else 30 if filt=='i' else 15 # 10\n",
    "            dirchoice = os.listdir(data_dir)[7]  # os.listdir(data_dir)[9] if filt=='z' else os.listdir(data_dir)[8]\n",
    "            if not manual_stack:\n",
    "                stack_name = f\"coadd_{dirchoice}_SDSS{filt}p_{exp:04d}s_RED_SW_{combtype}_{center_type}.fits\"\n",
    "                lab = f\"SDSS{filt}p_{exp:04d}s_RED_SW_{combtype}\"\n",
    "            else:\n",
    "                stack_name = f\"coadd_{dirchoice}_SDSS{filt}p_{exp:04d}s_RED_np{combtype}.fits\"\n",
    "                lab = f\"SDSS{filt}p_{exp:04d}s_RED_np{combtype}\"\n",
    "            with fits.open(stack_name) as stack_im:\n",
    "                hdr = stack_im[0].header\n",
    "                data = stack_im[0].data\n",
    "            mean, med, sigma = sigma_clipped_stats(data, sigma=3)\n",
    "            plt.imshow(data, cmap=\"gray\", vmin=med + 3 * sigma, vmax=med + 17 * sigma)\n",
    "            # plt.colorbar()\n",
    "            plt.title(lab)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dfcf51-a9e6-412c-9921-8c9c85518f72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python - DUAO",
   "language": "python",
   "name": "duao"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
